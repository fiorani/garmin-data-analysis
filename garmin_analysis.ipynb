{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inizializzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\"garmin_edge_820/summary.csv\", sep=\";\")\n",
    "details = pd.read_csv(\"garmin_edge_820/4557226804_ACTIVITY_data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "details = details.drop(['left_power_phase[degrees]',\n",
    "                        'left_power_phase_peak[degrees]',\n",
    "                        'right_power_phase[degrees]',\n",
    "                        'right_power_phase_peak[degrees]',\n",
    "                        'left_right_balance'], axis=1)\n",
    "# convertire i valori di tempo in formato datetime\n",
    "details['time'] = pd.to_datetime(details.pop('timestamp[s]'), unit='s').dt.time\n",
    "details.set_index(\"time\", inplace=True)\n",
    "\n",
    "# calcolo il tempo trascorso dall'inizio dell'attivit√†\n",
    "details['time_since_start'] = 1\n",
    "details['time_since_start'] = details['time_since_start'].cumsum().sub(1)\n",
    "\n",
    "# calcolo le zone di frequenza cardiaca e di potenza dato il battito in input\n",
    "\n",
    "hr_zones = [(0, 128), (129, 146), (147, 156), (157, 165),\n",
    "            (166, 174), (175, 179), (180, float('inf'))]\n",
    "power_zones = [(0, 157), (158, 186), (187, 200), (201, 218),\n",
    "               (219, 247), (248, 287), (288, float('inf'))]\n",
    "\n",
    "def get_zone(rate, zones):\n",
    "    for zone, (lower, upper) in enumerate(zones, start=1):\n",
    "        if lower <= rate <= upper:\n",
    "            return zone\n",
    "\n",
    "details['hr_zone'] = details['heart_rate[bpm]'].apply(get_zone, zones=hr_zones)\n",
    "details['pwr_zone'] = details['power[watts]'].apply(get_zone, zones=power_zones)\n",
    "\n",
    "# Calcola la differenza di altitudine tra le righe adiacenti\n",
    "details['altitude_diff'] = details['altitude[m]'] - \\\n",
    "    details['altitude[m]'].shift(1)\n",
    "details['distance_diff'] = details['distance[m]'] - \\\n",
    "    details['distance[m]'].shift(1)\n",
    "details[['altitude_diff', 'distance_diff']] = details[[\n",
    "    'altitude_diff', 'distance_diff']].fillna(0)\n",
    "# Calcola la percentuale di pendenza\n",
    "details['slope_percent'] = np.where(\n",
    "    details['distance_diff'] == 0, 0, details['altitude_diff'] / details['distance_diff'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details['speed[m/s]'] = details['speed[m/s]'].fillna(details['speed[m/s]'].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(details['time_since_start'], details['power[watts]'], label=\"power\")\n",
    "plt.plot(details['time_since_start'], details['cadence[rpm]'], label=\"cadence\")\n",
    "plt.plot(details['time_since_start'], details['speed[m/s]'], label=\"speed\")\n",
    "plt.plot(details['time_since_start'], details['heart_rate[bpm]'], label=\"bpm\")\n",
    "plt.plot(details['time_since_start'], details['altitude[m]'], label=\"altitude\")\n",
    "plt.xlabel(\"tempo\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definisco l'errore relativo\n",
    "def relative_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def print_eval(X, y, model):\n",
    "    preds = model.predict(X)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    re = relative_error(y, preds)\n",
    "    r2 = r2_score(y, preds)\n",
    "    print(f\"   Mean squared error: {mse:.5}\")\n",
    "    print(f\"       Relative error: {re:.5%}\")\n",
    "    print(f\"R-squared coefficient: {r2:.5}\")\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsione battito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = details.drop('heart_rate[bpm]', axis=1)\n",
    "y = details['heart_rate[bpm]']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione lineare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, lrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm = Lasso(alpha=0.3)\n",
    "lsm.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, lsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrm = Ridge(alpha=0.5)\n",
    "rrm.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, rrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enm = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "enm.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, enm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"linear\": lrm.coef_,\n",
    "    \"ridge\": rrm.coef_,\n",
    "    \"lasso\": lsm.coef_\n",
    "}, index=X_train.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione Polinomiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm_poly = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=4, include_bias=False)),\n",
    "    (\"linear\", LinearRegression())\n",
    "])\n",
    "lrm_poly.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, lrm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm_poly = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"lasso\", Lasso(alpha=0.7))\n",
    "])\n",
    "lsm_poly.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, lsm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrm_poly = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"ridge\", Ridge(alpha=1))\n",
    "])\n",
    "rrm_poly.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, rrm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enm_poly = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"elasticnet\", ElasticNet(alpha=0.1, l1_ratio=0.5))\n",
    "])\n",
    "enm_poly.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, enm_poly)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione polinomiale con standardizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm_poly_std = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"linear\", LinearRegression())\n",
    "])\n",
    "lrm_poly_std.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, lrm_poly_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm_poly_std = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"lasso\", Lasso(alpha=0.7))\n",
    "])\n",
    "lsm_poly_std.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, lsm_poly_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrm_poly_std = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha=1))\n",
    "])\n",
    "rrm_poly_std.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, rrm_poly_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enm_poly_std = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"elasticnet\", ElasticNet(alpha=0.1, l1_ratio=0.5))\n",
    "])\n",
    "enm_poly_std.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, enm_poly_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione con funzioni kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krm_poly = Pipeline([\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"kernel\", KernelRidge(alpha=20, kernel=\"poly\", degree=6))\n",
    "])\n",
    "krm_poly.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, krm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krm_rbf = Pipeline([\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"kernel\", KernelRidge(alpha=0.1, kernel=\"rbf\", gamma=0.1))\n",
    "])\n",
    "krm_rbf.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, krm_rbf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cross_validate(lrm, X, y, cv=kf, return_train_score=True)\n",
    "             ).describe().loc[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cross_validate(lrm_poly, X, y, cv=kf,\n",
    "             return_train_score=True)).describe().loc[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cross_validate(krm_rbf, X, y, cv=kf,\n",
    "             return_train_score=True)).describe().loc[[\"mean\", \"std\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tuning iperparametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoCV = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "    (\"std\", None),\n",
    "    (\"lasso\", Lasso())\n",
    "])\n",
    "\n",
    "grid = {\n",
    "    \"poly__degree\": np.arange(1, 5),\n",
    "    \"std\": [None, StandardScaler()],\n",
    "    \"lasso__alpha\": np.logspace(-3, 0, 10)\n",
    "}\n",
    "\n",
    "lasso_gs = GridSearchCV(lassoCV, grid, cv=kf, return_train_score=True)\n",
    "lasso_gs.fit(X_train, y_train)\n",
    "pd.DataFrame(lasso_gs.cv_results_).sort_values(\n",
    "    \"mean_test_score\", ascending=False)\n",
    "print_eval(X_val, y_val, lasso_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_ridgeCV(models):\n",
    "    scores = {}\n",
    "    for model in models:\n",
    "        mod, grid = model\n",
    "        gs = GridSearchCV(mod, grid, cv=kf, scoring='r2', return_train_score=True, n_jobs=-1)\n",
    "        gs.fit(X_train, y_train)\n",
    "        scores[str(mod['kernel_ridge__kernel'])] = gs.cv_results_\n",
    "\n",
    "# Definizione dei modelli\n",
    "models = [\n",
    "    (\n",
    "        Pipeline([\n",
    "            (\"std\", None),\n",
    "            (\"kernel_ridge\", KernelRidge(kernel='poly'))\n",
    "        ]),\n",
    "        {\n",
    "            'kernel_ridge__degree': range(1, 6),\n",
    "            'kernel_ridge__alpha': np.logspace(-3, 0, 10)\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        Pipeline([\n",
    "            (\"std\", None),\n",
    "            (\"kernel_ridge\", KernelRidge(kernel='rbf'))\n",
    "        ]),\n",
    "        {\n",
    "            'kernel_ridge__alpha': np.logspace(-3, 0, 10),\n",
    "            'kernel_ridge__gamma': np.logspace(-3, 0, 10)\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "# Esegui la ricerca del modello\n",
    "kernel_ridgeCV(models)\n",
    "\n",
    "# Accesso ai risultati\n",
    "for model, result in scores.items():\n",
    "    print(\"Model:\", model)\n",
    "    print(\"Mean R2 score:\", result['mean_test_score'])\n",
    "    print(\"Params:\", result['params'])\n",
    "    print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsione Potenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_details = details[details['power[watts]'] != 0]\n",
    "# Seleziona le colonne che saranno utilizzate come feature per la predizione\n",
    "features = copy_details.drop('power[watts]', axis=1)\n",
    "\n",
    "# Seleziona la colonna come target\n",
    "target = copy_details['power[watts]']\n",
    "\n",
    "# Dividi il dataset in set di addestramento e set di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea un'istanza del modello di regressione lineare\n",
    "pipe = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "    (\"std\", None),\n",
    "    (\"regressor\", None)\n",
    "])\n",
    "\n",
    "grid_common = {\n",
    "    \"poly__degree\": np.arange(1, 5),\n",
    "    \"std\": [None, StandardScaler()],\n",
    "}\n",
    "\n",
    "grid_regressors = [\n",
    "    {\n",
    "        \"regressor\": [LinearRegression()],\n",
    "    },\n",
    "    {\n",
    "        \"regressor\": [Lasso()],\n",
    "        \"regressor__alpha\": np.logspace(-3, 0, 10),\n",
    "    },\n",
    "    {\n",
    "        \"regressor\": [Ridge()],\n",
    "        \"regressor__alpha\": np.logspace(-3, 0, 10),\n",
    "    },\n",
    "    {\n",
    "        \"regressor\": [ElasticNet()],\n",
    "        \"regressor__alpha\": np.logspace(-3, 0, 10),\n",
    "        \"regressor__l1_ratio\": np.linspace(0, 1, 5)\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = [dict(grid_common, **params) for params in grid_regressors]\n",
    "\n",
    "#model = GridSearchCV(pipe, grid, cv=kf, scoring='r2', n_jobs=-1)\n",
    "model = Pipeline([\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"kernel\", KernelRidge(alpha=0.1, kernel=\"rbf\", gamma=0.1))\n",
    "])\n",
    "# Addestra il modello sui dati di addestramento\n",
    "model.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model)\n",
    "# Effettua la predizione sul set di test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ora puoi utilizzare il modello addestrato per predire nuovi dati\n",
    "#new_data = pd.DataFrame([[4, 140, 90]], columns=features)\n",
    "#watts_pred = model.predict(new_data)\n",
    "#print(\"Potenza predetta:\", watts_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificazione della potenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = details[[\"time_since_start\", \"power[watts]\"]]\n",
    "y = details['pwr_zone']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "diagnosis_color_map = {1: \"yellow\", 2: \"orange\", 3: \"red\",\n",
    "                       4: \"purple\", 5: \"blue\", 6: \"green\", 7: \"black\"}\n",
    "X_train.plot.scatter(\"time_since_start\", \"power[watts]\",\n",
    "                     c=y_train.map(diagnosis_color_map),\n",
    "                     figsize=(24, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_counts = details['pwr_zone'].value_counts()\n",
    "\n",
    "zone_counts.plot.barh(figsize=(24, 6), legend=None)\n",
    "\n",
    "plt.xlabel('tempo')\n",
    "plt.ylabel('Zona')\n",
    "plt.title('Conteggio del tempo a seconda delle zone')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "X = details.drop(['pwr_zone'], axis=1)\n",
    "y = details['pwr_zone']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=7)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(24, 9))\n",
    "plot_tree(model, feature_names=X_train.columns.to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
