{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install numpy\n",
    "#%pip install pandas\n",
    "#%pip install matplotlib\n",
    "#%pip install scikit-learn\n",
    "#%pip install lightgbm\n",
    "#%pip install xgboost\n",
    "#%pip install flask\n",
    "#%pip install torch\n",
    "#%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"garmin_edge_820/3993730634_ACTIVITY_data.csv\",\n",
    "             \"garmin_edge_820/4557226804_ACTIVITY_data.csv\",\n",
    "             \"garmin_edge_820/4593452980_ACTIVITY_data.csv\",\n",
    "             \"garmin_edge_820/5191513011_ACTIVITY_data.csv\",\n",
    "]\n",
    "combined_df = pd.concat([pd.read_csv(file, sep=\";\") for file in file_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_brackets(string):\n",
    "    return string.replace('[', '(').replace(']', ')')\n",
    "\n",
    "combined_df.columns = [convert_brackets(col) for col in combined_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_zones = [(0, 128), (129, 146), (147, 156), (157, 165),(166, 174), (175, 179), (180, float('inf'))]\n",
    "power_zones = [(0, 157), (158, 186), (187, 200), (201, 218),(219, 247), (248, 287), (288, float('inf'))]\n",
    "\n",
    "def get_zone(rate, zones):\n",
    "    for zone, (lower, upper) in enumerate(zones, start=0):\n",
    "        if lower <= rate <= upper:\n",
    "            return zone\n",
    "        \n",
    "combined_df['hr_zone'] = combined_df['heart_rate(bpm)'].apply(get_zone, zones=hr_zones)\n",
    "combined_df['pwr_zone'] = combined_df['power(watts)'].apply(get_zone, zones=power_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20 \n",
    "combined_df['altitude_diff(m)'] = combined_df['altitude(m)'] - combined_df['altitude(m)'].shift(1)\n",
    "combined_df['distance_diff(m)'] = combined_df['distance(m)'] - combined_df['distance(m)'].shift(1)\n",
    "combined_df[['altitude_diff(m)', 'distance_diff(m)']] = combined_df[['altitude_diff(m)', 'distance_diff(m)']].fillna(0)\n",
    "combined_df['slope_percent'] = np.where(combined_df['distance_diff(m)'] == 0, 0, combined_df['altitude_diff(m)'] / combined_df['distance_diff(m)'] * 100)\n",
    "combined_df['avg_slope_percent'] = combined_df['slope_percent'].rolling(window=int(window_size), center=True).mean()\n",
    "combined_df = combined_df.dropna(subset=['avg_slope_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "combined_df['avg_power(watts)'] = combined_df['power(watts)'].rolling(window=int(window_size), center=True).mean()\n",
    "combined_df = combined_df.dropna(subset=['avg_power(watts)'])\n",
    "combined_df['avg_power(watts)'] = combined_df['avg_power(watts)'].astype('int64')\n",
    "combined_df = combined_df[combined_df['avg_power(watts)'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['power_left(watts)'] = combined_df['left_right_balance'] - 128\n",
    "combined_df['power_right(watts)'] = 100 - combined_df['power_left(watts)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['speed(m/s)'] > 0]\n",
    "combined_df = combined_df[(combined_df['power(watts)'] > 0) & (combined_df['power(watts)'] < 600)]\n",
    "combined_df = combined_df[combined_df['cadence(rpm)'] > 0]\n",
    "combined_df = combined_df[combined_df['heart_rate(bpm)'] > 80]\n",
    "combined_df = combined_df.dropna(subset=['speed(m/s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['timestamp(s)'] = combined_df['timestamp(s)'] + 631065600\n",
    "combined_df['time'] = pd.to_datetime(combined_df.pop('timestamp(s)'), unit='s')\n",
    "combined_df.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['time_since_start(s)'] = combined_df.groupby(pd.Grouper(freq='D')).cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.drop(['left_power_phase(degrees)',\n",
    "                            'left_power_phase_peak(degrees)',\n",
    "                            'right_power_phase(degrees)',\n",
    "                            'right_power_phase_peak(degrees)',\n",
    "                            'left_right_balance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsione battito (regressione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = combined_df.drop(['heart_rate(bpm)','altitude(m)','avg_power(watts)','slope_percent','temperature(C)','hr_zone','pwr_zone','altitude_diff(m)','distance_diff(m)','left_pco(mm)','right_pco(mm)','power_left(watts)','power_right(watts)','accumulated_power(watts)'], axis=1)\n",
    "y = combined_df['heart_rate(bpm)']\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36523, 17989)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to numpy arrays\n",
    "x_np = x.to_numpy(dtype=np.float32)\n",
    "y_np = y.to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "# Normalize the data\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "x_np = scaler_x.fit_transform(x_np)\n",
    "y_np = scaler_y.fit_transform(y_np)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_tensor = torch.tensor(x_np)\n",
    "y_tensor = torch.tensor(y_np)\n",
    "\n",
    "# Create a dataset from tensors\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.67 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "train_size, val_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartRatePredictor(\n",
       "  (fc1): Linear(in_features=6, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HeartRatePredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HeartRatePredictor, self).__init__()\n",
    "        \n",
    "        # Define the architecture\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n",
    "# Create the model\n",
    "input_dim = x.shape[1]\n",
    "model = HeartRatePredictor(input_dim)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Loss: 0.1775: 100%|█████████▉| 28549/28550 [01:33<00:00, 307.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Loss: 0.1775: 100%|██████████| 28550/28550 [01:33<00:00, 304.74it/s]\n",
      "Validation:  90%|█████████ | 255/282 [00:00<00:00, 1267.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2038\n"
     ]
    }
   ],
   "source": [
    "# Define the loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "# Create a single tqdm object for the entire training process\n",
    "pbar = tqdm(total=num_epochs * len(train_loader), position=0, leave=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar\n",
    "        desc = f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/(i+1):.4f}\"\n",
    "        pbar.set_description(desc)\n",
    "        pbar.update(1)\n",
    "    \n",
    "print(\"Finished Training\")\n",
    "\n",
    "# Reset the tqdm progress bar for validation\n",
    "pbar = tqdm(total=len(val_loader), position=0, leave=True, desc=\"Validation\")\n",
    "\n",
    "# Evaluate the model on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar for validation\n",
    "        pbar.update(1)\n",
    "        \n",
    "    print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.3104\n",
      "MSE: 0.2042\n",
      "RMSE: 0.4519\n",
      "R^2: 0.7985\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "y_preds = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        y_preds.append(outputs)\n",
    "        y_true.append(labels)\n",
    "\n",
    "# Concatenate the results\n",
    "y_pred = torch.cat(y_preds, dim=0)\n",
    "y_val = torch.cat(y_true, dim=0)\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "y_val_np = y_val.numpy()\n",
    "y_pred_np = y_pred.numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_val_np, y_pred_np)\n",
    "mse = np.mean((y_val_np - y_pred_np)**2)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val_np, y_pred_np)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione zone frequenza cardiaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = combined_df[[\"time_since_start(s)\", \"heart_rate(bpm)\"]]\n",
    "y = combined_df['hr_zone']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36523, 17989)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to numpy arrays\n",
    "x_np = x.to_numpy(dtype=np.float32)\n",
    "y_np = y.to_numpy(dtype=np.int64)\n",
    "\n",
    "# Normalize the data\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "x_np = scaler_x.fit_transform(x_np)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_tensor = torch.tensor(x_np)\n",
    "y_tensor = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "# Create a dataset from tensors\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.67 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "train_size, val_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartRateZoneClassifier(\n",
       "  (fc1): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HeartRateZoneClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(HeartRateZoneClassifier, self).__init__()\n",
    "        \n",
    "        # Define the architecture\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return F.softmax(self.fc4(x), dim=1)\n",
    "\n",
    "# Create the classification model\n",
    "input_dim = x.shape[1]\n",
    "num_classes = len(hr_zones)\n",
    "model = HeartRateZoneClassifier(input_dim, num_classes)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 282/282 [00:00<00:00, 563.56it/s] \n",
      "Epoch 50/50 - Loss: 1.2533: 100%|██████████| 28550/28550 [01:49<00:00, 259.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:  70%|██████▉   | 196/282 [00:00<00:00, 977.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 91.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 282/282 [00:16<00:00, 977.97it/s]"
     ]
    }
   ],
   "source": [
    "# Define the loss and optimizer for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "pbar = tqdm(total=num_epochs * len(train_loader), position=0, leave=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Update the progress bar\n",
    "        desc = f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/(i+1):.4f}\"\n",
    "        pbar.set_description(desc)\n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# Reset the tqdm progress bar for validation\n",
    "pbar = tqdm(total=len(val_loader), position=0, leave=True, desc=\"Validation\")\n",
    "\n",
    "# Evaluate the model on validation set\n",
    "model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        val_total += labels.size(0)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update the progress bar for validation\n",
    "        pbar.update(1)\n",
    "        \n",
    "    print(f\"Validation Accuracy: {val_correct/val_total*100:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
